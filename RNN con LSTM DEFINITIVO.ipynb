{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66ca1534",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-12 23:04:59.530110: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-05-12 23:04:59.530216: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from gensim.utils import simple_preprocess\n",
    "from nltk.corpus import stopwords\n",
    "import gensim\n",
    "from sklearn.model_selection import train_test_split\n",
    "import spacy\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8690f85b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>El Atl√©tico resignado a perder HASHTAG üòî  http...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Leer proporciona una mejor visi√≥n del mundo ü§ì ...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Amo a Arya Stark por encima de todas las cosas...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gracias HASHTAG es incre√≠ble que una ni√±a logr...</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Solo siento que hayamos perdido 24 esca√±os de ...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              tweet     label\n",
       "0   1  El Atl√©tico resignado a perder HASHTAG üòî  http...  sadness \n",
       "1   2  Leer proporciona una mejor visi√≥n del mundo ü§ì ...      joy \n",
       "2   3  Amo a Arya Stark por encima de todas las cosas...      joy \n",
       "3   4  Gracias HASHTAG es incre√≠ble que una ni√±a logr...    others\n",
       "4   5  Solo siento que hayamos perdido 24 esca√±os de ...  sadness "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('tass2020_emotion_train.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77a759c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sadness ', 'joy ', 'others', 'others ', 'surprise ', 'disgust ',\n",
       "       'anger ', 'fear '], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee3c5663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>anger</th>\n",
       "      <td>600</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disgust</th>\n",
       "      <td>113</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joy</th>\n",
       "      <td>1270</td>\n",
       "      <td>1270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>others</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>others</th>\n",
       "      <td>2888</td>\n",
       "      <td>2886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sadness</th>\n",
       "      <td>706</td>\n",
       "      <td>706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surprise</th>\n",
       "      <td>241</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  tweet\n",
       "label                 \n",
       "anger       600    600\n",
       "disgust     113    113\n",
       "fear         67     67\n",
       "joy        1270   1270\n",
       "others        1      1\n",
       "others     2888   2886\n",
       "sadness     706    706\n",
       "surprise    241    241"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby('label').nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cf4eb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[['tweet','label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84d9d1b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"tweet\"].isnull().sum() #No hay valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8b96043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['El Atl√©tico resignado a perder HASHTAG üòî ',\n",
       " 'Leer proporciona una mejor visi√≥n del mundo ü§ì ¬°Feliz HASHTAG y HASHTAG! üìñ ',\n",
       " 'Amo a Arya Stark por encima de todas las cosas üòçüòçüòç#gameofthrones HASHTAG',\n",
       " 'Gracias HASHTAG es incre√≠ble que una ni√±a logre liderar tan imperativa movilizaci√≥n y supere a cualquier adulto en nivel de conciencia. Verg√ºenza deber√≠amos sentir los dem√°s üòì#CambioClim√°tico HASHTAG HASHTAG HASHTAG üôèüåéüíö',\n",
       " 'Solo siento que hayamos perdido 24 esca√±os de cordura HASHTAG']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def depure_data(data):\n",
    "    \n",
    "    #Removing URLs with a regular expression\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    data = url_pattern.sub(r'', data)\n",
    "\n",
    "    # Remove Emails\n",
    "    data = re.sub('\\S*@\\S*\\s?', '', data)\n",
    "\n",
    "    # Remove new line characters\n",
    "    data = re.sub('\\s+', ' ', data)\n",
    "\n",
    "    # Remove distracting single quotes\n",
    "    data = re.sub(\"\\'\", \"\", data)\n",
    "        \n",
    "    return data\n",
    "\n",
    "temp = []\n",
    "#Splitting pd.Series to list\n",
    "data_to_list = train['tweet'].values.tolist()\n",
    "for i in range(len(data_to_list)):\n",
    "    temp.append(depure_data(data_to_list[i]))\n",
    "list(temp[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9da8d5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['el', 'atletico', 'resignado', 'perder', 'hashtag'], ['leer', 'proporciona', 'una', 'mejor', 'vision', 'del', 'mundo', 'feliz', 'hashtag', 'hashtag'], ['amo', 'arya', 'stark', 'por', 'encima', 'de', 'todas', 'las', 'cosas', 'gameofthrones', 'hashtag'], ['gracias', 'hashtag', 'es', 'increible', 'que', 'una', 'nina', 'logre', 'liderar', 'tan', 'imperativa', 'movilizacion', 'supere', 'cualquier', 'adulto', 'en', 'nivel', 'de', 'conciencia', 'verguenza', 'deberiamos', 'sentir', 'los', 'demas', 'cambioclimatico', 'hashtag', 'hashtag', 'hashtag'], ['solo', 'siento', 'que', 'hayamos', 'perdido', 'escanos', 'de', 'cordura', 'hashtag'], ['solo', 'con', 'ver', 'con', 'la', 'intensidad', 'que', 'agitan', 'las', 'banderas', 'se', 've', 'que', 'no', 'han', 'quedado', 'satisfechos', 'los', 'de', 'user', 'sinceramente', 'me', 'alegro', 'muchisimo', 'hashtag', 'hashtag'], ['una', 'vez', 'mas', 'uno', 'de', 'los', 'mejores', 'jugadores', 'de', 'la', 'historia', 'leo', 'messi', 'al', 'al', 'en', 'hashtag', 'se', 'acabo', 'la', 'serie'], ['hashtag', 'espero', 'que', 'no', 'se', 'quejen', 'de', 'los', 'injusto', 'que', 'es', 'el', 'futbol'], ['hoy', 'tarde', 'de', 'oraciones', 'pido', 'por', 'todos', 'mis', 'amigos', 'venezolanos', 'que', 'hoy', 'sufren', 'la', 'opresion', 'fin', 'de', 'que', 'llegue', 'pronto', 'una', 'hashtag', 'sin', 'violencia'], ['hashtag', 'el', 'mundo', 'nos', 'necesita', 'asi', 'que', 'es', 'hora', 'de', 'alzar', 'la', 'voz']]\n"
     ]
    }
   ],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "        \n",
    "\n",
    "data_words = list(sent_to_words(temp))\n",
    "\n",
    "print(data_words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e28f50eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['el atletico resignado perder hashtag', 'leer proporciona una mejor vision del mundo feliz hashtag hashtag', 'amo arya stark por encima de todas las cosas gameofthrones hashtag', 'gracias hashtag es increible que una nina logre liderar tan imperativa movilizacion supere cualquier adulto en nivel de conciencia verguenza deberiamos sentir los demas cambioclimatico hashtag hashtag hashtag', 'solo siento que hayamos perdido escanos de cordura hashtag']\n"
     ]
    }
   ],
   "source": [
    "def detokenize(text):\n",
    "    return TreebankWordDetokenizer().detokenize(text)\n",
    "\n",
    "data = []\n",
    "for i in range(len(data_words)):\n",
    "    data.append(detokenize(data_words[i]))\n",
    "print(data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "baa3d7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8874154a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(train['label'])\n",
    "y = []\n",
    "for i in labels:\n",
    "    if i == 'anger ':\n",
    "        y.append(0)\n",
    "    if i == 'disgust ':\n",
    "        y.append(1)\n",
    "    if i == 'fear ':\n",
    "        y.append(2)\n",
    "    if i == 'joy ':\n",
    "        y.append(3)\n",
    "    if i == 'others ':\n",
    "        y.append(4)\n",
    "    if i == 'others':\n",
    "        y.append(4)\n",
    "    if i == 'sadness ':\n",
    "        y.append(5)\n",
    "    if i == 'surprise ':\n",
    "        y.append(6)\n",
    "y = np.array(y)\n",
    "labels = tf.keras.utils.to_categorical(y, 7,dtype=\"float32\")\n",
    "del y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1e40783a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5886"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "00005ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0 ...  700  360    1]\n",
      " [   0    0    0 ...   65    1    1]\n",
      " [   0    0    0 ...  182 3571    1]\n",
      " ...\n",
      " [   0    0    0 ...    1   10  568]\n",
      " [   0    0    0 ...    1    1    1]\n",
      " [   0    0    0 ...   48    1    1]]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "max_words = 5000\n",
    "max_len = 200\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(data)\n",
    "sequences = tokenizer.texts_to_sequences(data)\n",
    "tweets = pad_sequences(sequences, maxlen=max_len)\n",
    "print(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5b9ed0d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fdc25cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4414 1472 4414 1472\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(tweets,labels, random_state=0)\n",
    "print (len(X_train),len(X_test),len(y_train),len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "066021d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 1.5212 - accuracy: 0.4844\n",
      "Epoch 1: val_accuracy improved from -inf to 0.48709, saving model to best_model1.hdf5\n",
      "138/138 [==============================] - 23s 126ms/step - loss: 1.5212 - accuracy: 0.4844 - val_loss: 1.4343 - val_accuracy: 0.4871\n",
      "Epoch 2/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 1.3803 - accuracy: 0.4941\n",
      "Epoch 2: val_accuracy improved from 0.48709 to 0.49321, saving model to best_model1.hdf5\n",
      "138/138 [==============================] - 16s 114ms/step - loss: 1.3803 - accuracy: 0.4941 - val_loss: 1.3784 - val_accuracy: 0.4932\n",
      "Epoch 3/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 1.3267 - accuracy: 0.5109\n",
      "Epoch 3: val_accuracy improved from 0.49321 to 0.51223, saving model to best_model1.hdf5\n",
      "138/138 [==============================] - 16s 114ms/step - loss: 1.3267 - accuracy: 0.5109 - val_loss: 1.3396 - val_accuracy: 0.5122\n",
      "Epoch 4/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 1.2680 - accuracy: 0.5372\n",
      "Epoch 4: val_accuracy improved from 0.51223 to 0.52514, saving model to best_model1.hdf5\n",
      "138/138 [==============================] - 16s 113ms/step - loss: 1.2680 - accuracy: 0.5372 - val_loss: 1.3018 - val_accuracy: 0.5251\n",
      "Epoch 5/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 1.2109 - accuracy: 0.5541\n",
      "Epoch 5: val_accuracy improved from 0.52514 to 0.53533, saving model to best_model1.hdf5\n",
      "138/138 [==============================] - 16s 115ms/step - loss: 1.2109 - accuracy: 0.5541 - val_loss: 1.2687 - val_accuracy: 0.5353\n",
      "Epoch 6/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 1.1563 - accuracy: 0.5598\n",
      "Epoch 6: val_accuracy did not improve from 0.53533\n",
      "138/138 [==============================] - 16s 115ms/step - loss: 1.1563 - accuracy: 0.5598 - val_loss: 1.2499 - val_accuracy: 0.5333\n",
      "Epoch 7/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 1.1173 - accuracy: 0.5748\n",
      "Epoch 7: val_accuracy improved from 0.53533 to 0.54280, saving model to best_model1.hdf5\n",
      "138/138 [==============================] - 16s 115ms/step - loss: 1.1173 - accuracy: 0.5748 - val_loss: 1.2491 - val_accuracy: 0.5428\n",
      "Epoch 8/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 1.0776 - accuracy: 0.5979\n",
      "Epoch 8: val_accuracy improved from 0.54280 to 0.55571, saving model to best_model1.hdf5\n",
      "138/138 [==============================] - 16s 116ms/step - loss: 1.0776 - accuracy: 0.5979 - val_loss: 1.2279 - val_accuracy: 0.5557\n",
      "Epoch 9/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 1.0353 - accuracy: 0.6269\n",
      "Epoch 9: val_accuracy improved from 0.55571 to 0.57609, saving model to best_model1.hdf5\n",
      "138/138 [==============================] - 16s 116ms/step - loss: 1.0353 - accuracy: 0.6269 - val_loss: 1.1965 - val_accuracy: 0.5761\n",
      "Epoch 10/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.9891 - accuracy: 0.6581\n",
      "Epoch 10: val_accuracy did not improve from 0.57609\n",
      "138/138 [==============================] - 16s 115ms/step - loss: 0.9891 - accuracy: 0.6581 - val_loss: 1.1825 - val_accuracy: 0.5700\n",
      "Epoch 11/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.9497 - accuracy: 0.6695\n",
      "Epoch 11: val_accuracy did not improve from 0.57609\n",
      "138/138 [==============================] - 16s 119ms/step - loss: 0.9497 - accuracy: 0.6695 - val_loss: 1.1900 - val_accuracy: 0.5727\n",
      "Epoch 12/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.9140 - accuracy: 0.6842\n",
      "Epoch 12: val_accuracy did not improve from 0.57609\n",
      "138/138 [==============================] - 16s 113ms/step - loss: 0.9140 - accuracy: 0.6842 - val_loss: 1.2222 - val_accuracy: 0.5761\n",
      "Epoch 13/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.8944 - accuracy: 0.6939\n",
      "Epoch 13: val_accuracy improved from 0.57609 to 0.58084, saving model to best_model1.hdf5\n",
      "138/138 [==============================] - 16s 116ms/step - loss: 0.8944 - accuracy: 0.6939 - val_loss: 1.2088 - val_accuracy: 0.5808\n",
      "Epoch 14/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.8739 - accuracy: 0.7043\n",
      "Epoch 14: val_accuracy did not improve from 0.58084\n",
      "138/138 [==============================] - 16s 114ms/step - loss: 0.8739 - accuracy: 0.7043 - val_loss: 1.2015 - val_accuracy: 0.5673\n",
      "Epoch 15/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.8412 - accuracy: 0.7173\n",
      "Epoch 15: val_accuracy did not improve from 0.58084\n",
      "138/138 [==============================] - 16s 115ms/step - loss: 0.8412 - accuracy: 0.7173 - val_loss: 1.2294 - val_accuracy: 0.5611\n",
      "Epoch 16/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.8176 - accuracy: 0.7161\n",
      "Epoch 16: val_accuracy did not improve from 0.58084\n",
      "138/138 [==============================] - 16s 115ms/step - loss: 0.8176 - accuracy: 0.7161 - val_loss: 1.2208 - val_accuracy: 0.5713\n",
      "Epoch 17/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.7989 - accuracy: 0.7275\n",
      "Epoch 17: val_accuracy improved from 0.58084 to 0.58560, saving model to best_model1.hdf5\n",
      "138/138 [==============================] - 16s 113ms/step - loss: 0.7989 - accuracy: 0.7275 - val_loss: 1.2253 - val_accuracy: 0.5856\n",
      "Epoch 18/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.7863 - accuracy: 0.7401\n",
      "Epoch 18: val_accuracy improved from 0.58560 to 0.59103, saving model to best_model1.hdf5\n",
      "138/138 [==============================] - 16s 115ms/step - loss: 0.7863 - accuracy: 0.7401 - val_loss: 1.2478 - val_accuracy: 0.5910\n",
      "Epoch 19/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.7621 - accuracy: 0.7458\n",
      "Epoch 19: val_accuracy did not improve from 0.59103\n",
      "138/138 [==============================] - 16s 113ms/step - loss: 0.7621 - accuracy: 0.7458 - val_loss: 1.2621 - val_accuracy: 0.5679\n",
      "Epoch 20/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.7548 - accuracy: 0.7497\n",
      "Epoch 20: val_accuracy improved from 0.59103 to 0.59443, saving model to best_model1.hdf5\n",
      "138/138 [==============================] - 16s 114ms/step - loss: 0.7548 - accuracy: 0.7497 - val_loss: 1.2680 - val_accuracy: 0.5944\n",
      "Epoch 21/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.7343 - accuracy: 0.7558\n",
      "Epoch 21: val_accuracy did not improve from 0.59443\n",
      "138/138 [==============================] - 16s 117ms/step - loss: 0.7343 - accuracy: 0.7558 - val_loss: 1.2684 - val_accuracy: 0.5584\n",
      "Epoch 22/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.7158 - accuracy: 0.7617\n",
      "Epoch 22: val_accuracy did not improve from 0.59443\n",
      "138/138 [==============================] - 16s 118ms/step - loss: 0.7158 - accuracy: 0.7617 - val_loss: 1.3567 - val_accuracy: 0.5442\n",
      "Epoch 23/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.7061 - accuracy: 0.7617\n",
      "Epoch 23: val_accuracy did not improve from 0.59443\n",
      "138/138 [==============================] - 17s 121ms/step - loss: 0.7061 - accuracy: 0.7617 - val_loss: 1.3049 - val_accuracy: 0.5849\n",
      "Epoch 24/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.6845 - accuracy: 0.7700\n",
      "Epoch 24: val_accuracy did not improve from 0.59443\n",
      "138/138 [==============================] - 17s 121ms/step - loss: 0.6845 - accuracy: 0.7700 - val_loss: 1.3135 - val_accuracy: 0.5836\n",
      "Epoch 25/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.6768 - accuracy: 0.7750\n",
      "Epoch 25: val_accuracy did not improve from 0.59443\n",
      "138/138 [==============================] - 16s 117ms/step - loss: 0.6768 - accuracy: 0.7750 - val_loss: 1.3580 - val_accuracy: 0.5822\n",
      "Epoch 26/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.6634 - accuracy: 0.7764\n",
      "Epoch 26: val_accuracy did not improve from 0.59443\n",
      "138/138 [==============================] - 17s 121ms/step - loss: 0.6634 - accuracy: 0.7764 - val_loss: 1.3166 - val_accuracy: 0.5876\n",
      "Epoch 27/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.6551 - accuracy: 0.7814\n",
      "Epoch 27: val_accuracy did not improve from 0.59443\n",
      "138/138 [==============================] - 16s 117ms/step - loss: 0.6551 - accuracy: 0.7814 - val_loss: 1.3399 - val_accuracy: 0.5611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.6446 - accuracy: 0.7873\n",
      "Epoch 28: val_accuracy did not improve from 0.59443\n",
      "138/138 [==============================] - 17s 123ms/step - loss: 0.6446 - accuracy: 0.7873 - val_loss: 1.3587 - val_accuracy: 0.5815\n",
      "Epoch 29/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.6307 - accuracy: 0.7884\n",
      "Epoch 29: val_accuracy did not improve from 0.59443\n",
      "138/138 [==============================] - 16s 115ms/step - loss: 0.6307 - accuracy: 0.7884 - val_loss: 1.3426 - val_accuracy: 0.5781\n",
      "Epoch 30/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.6220 - accuracy: 0.7923\n",
      "Epoch 30: val_accuracy did not improve from 0.59443\n",
      "138/138 [==============================] - 16s 114ms/step - loss: 0.6220 - accuracy: 0.7923 - val_loss: 1.3475 - val_accuracy: 0.5761\n",
      "Epoch 31/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.6074 - accuracy: 0.8029\n",
      "Epoch 31: val_accuracy did not improve from 0.59443\n",
      "138/138 [==============================] - 16s 114ms/step - loss: 0.6074 - accuracy: 0.8029 - val_loss: 1.3909 - val_accuracy: 0.5822\n",
      "Epoch 32/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.6035 - accuracy: 0.8058\n",
      "Epoch 32: val_accuracy did not improve from 0.59443\n",
      "138/138 [==============================] - 16s 113ms/step - loss: 0.6035 - accuracy: 0.8058 - val_loss: 1.3850 - val_accuracy: 0.5747\n",
      "Epoch 33/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.5972 - accuracy: 0.8052\n",
      "Epoch 33: val_accuracy did not improve from 0.59443\n",
      "138/138 [==============================] - 16s 116ms/step - loss: 0.5972 - accuracy: 0.8052 - val_loss: 1.4049 - val_accuracy: 0.5808\n",
      "Epoch 34/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.5846 - accuracy: 0.8079\n",
      "Epoch 34: val_accuracy did not improve from 0.59443\n",
      "138/138 [==============================] - 16s 117ms/step - loss: 0.5846 - accuracy: 0.8079 - val_loss: 1.3835 - val_accuracy: 0.5727\n",
      "Epoch 35/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.5637 - accuracy: 0.8115\n",
      "Epoch 35: val_accuracy did not improve from 0.59443\n",
      "138/138 [==============================] - 16s 117ms/step - loss: 0.5637 - accuracy: 0.8115 - val_loss: 1.4061 - val_accuracy: 0.5707\n",
      "Epoch 36/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.5762 - accuracy: 0.8063\n",
      "Epoch 36: val_accuracy did not improve from 0.59443\n",
      "138/138 [==============================] - 17s 124ms/step - loss: 0.5762 - accuracy: 0.8063 - val_loss: 1.4031 - val_accuracy: 0.5686\n",
      "Epoch 37/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.5573 - accuracy: 0.8122\n",
      "Epoch 37: val_accuracy did not improve from 0.59443\n",
      "138/138 [==============================] - 16s 116ms/step - loss: 0.5573 - accuracy: 0.8122 - val_loss: 1.4277 - val_accuracy: 0.5727\n",
      "Epoch 38/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.5482 - accuracy: 0.8165\n",
      "Epoch 38: val_accuracy did not improve from 0.59443\n",
      "138/138 [==============================] - 16s 115ms/step - loss: 0.5482 - accuracy: 0.8165 - val_loss: 1.4163 - val_accuracy: 0.5679\n",
      "Epoch 39/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.5382 - accuracy: 0.8224\n",
      "Epoch 39: val_accuracy did not improve from 0.59443\n",
      "138/138 [==============================] - 16s 116ms/step - loss: 0.5382 - accuracy: 0.8224 - val_loss: 1.4473 - val_accuracy: 0.5611\n",
      "Epoch 40/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.5394 - accuracy: 0.8197\n",
      "Epoch 40: val_accuracy did not improve from 0.59443\n",
      "138/138 [==============================] - 16s 117ms/step - loss: 0.5394 - accuracy: 0.8197 - val_loss: 1.4250 - val_accuracy: 0.5645\n",
      "Epoch 41/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.5326 - accuracy: 0.8301\n",
      "Epoch 41: val_accuracy did not improve from 0.59443\n",
      "138/138 [==============================] - 16s 115ms/step - loss: 0.5326 - accuracy: 0.8301 - val_loss: 1.4484 - val_accuracy: 0.5679\n",
      "Epoch 42/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.5254 - accuracy: 0.8237\n",
      "Epoch 42: val_accuracy did not improve from 0.59443\n",
      "138/138 [==============================] - 16s 115ms/step - loss: 0.5254 - accuracy: 0.8237 - val_loss: 1.4375 - val_accuracy: 0.5639\n",
      "Epoch 43/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.5023 - accuracy: 0.8319\n",
      "Epoch 43: val_accuracy did not improve from 0.59443\n",
      "138/138 [==============================] - 16s 115ms/step - loss: 0.5023 - accuracy: 0.8319 - val_loss: 1.4687 - val_accuracy: 0.5666\n",
      "Epoch 44/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.5014 - accuracy: 0.8330\n",
      "Epoch 44: val_accuracy did not improve from 0.59443\n",
      "138/138 [==============================] - 16s 118ms/step - loss: 0.5014 - accuracy: 0.8330 - val_loss: 1.4517 - val_accuracy: 0.5659\n",
      "Epoch 45/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.5013 - accuracy: 0.8367\n",
      "Epoch 45: val_accuracy did not improve from 0.59443\n",
      "138/138 [==============================] - 16s 117ms/step - loss: 0.5013 - accuracy: 0.8367 - val_loss: 1.5412 - val_accuracy: 0.5591\n",
      "Epoch 46/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.4888 - accuracy: 0.8380\n",
      "Epoch 46: val_accuracy did not improve from 0.59443\n",
      "138/138 [==============================] - 16s 115ms/step - loss: 0.4888 - accuracy: 0.8380 - val_loss: 1.4911 - val_accuracy: 0.5673\n",
      "Epoch 47/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.4915 - accuracy: 0.8380\n",
      "Epoch 47: val_accuracy did not improve from 0.59443\n",
      "138/138 [==============================] - 16s 115ms/step - loss: 0.4915 - accuracy: 0.8380 - val_loss: 1.5036 - val_accuracy: 0.5652\n",
      "Epoch 48/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.4777 - accuracy: 0.8410\n",
      "Epoch 48: val_accuracy did not improve from 0.59443\n",
      "138/138 [==============================] - 16s 115ms/step - loss: 0.4777 - accuracy: 0.8410 - val_loss: 1.4861 - val_accuracy: 0.5571\n",
      "Epoch 49/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.4649 - accuracy: 0.8464\n",
      "Epoch 49: val_accuracy did not improve from 0.59443\n",
      "138/138 [==============================] - 16s 115ms/step - loss: 0.4649 - accuracy: 0.8464 - val_loss: 1.5295 - val_accuracy: 0.5503\n",
      "Epoch 50/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.4659 - accuracy: 0.8459\n",
      "Epoch 50: val_accuracy did not improve from 0.59443\n",
      "138/138 [==============================] - 16s 116ms/step - loss: 0.4659 - accuracy: 0.8459 - val_loss: 1.6008 - val_accuracy: 0.5367\n",
      "Epoch 51/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.4684 - accuracy: 0.8448\n",
      "Epoch 51: val_accuracy did not improve from 0.59443\n",
      "138/138 [==============================] - 16s 115ms/step - loss: 0.4684 - accuracy: 0.8448 - val_loss: 1.5375 - val_accuracy: 0.5448\n",
      "Epoch 52/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.4661 - accuracy: 0.8425\n",
      "Epoch 52: val_accuracy did not improve from 0.59443\n",
      "138/138 [==============================] - 16s 115ms/step - loss: 0.4661 - accuracy: 0.8425 - val_loss: 1.5237 - val_accuracy: 0.5747\n",
      "Epoch 53/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.4580 - accuracy: 0.8469\n",
      "Epoch 53: val_accuracy did not improve from 0.59443\n",
      "138/138 [==============================] - 16s 115ms/step - loss: 0.4580 - accuracy: 0.8469 - val_loss: 1.5386 - val_accuracy: 0.5618\n",
      "Epoch 54/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.4559 - accuracy: 0.8493\n",
      "Epoch 54: val_accuracy did not improve from 0.59443\n",
      "138/138 [==============================] - 16s 115ms/step - loss: 0.4559 - accuracy: 0.8493 - val_loss: 1.4898 - val_accuracy: 0.5652\n",
      "Epoch 55/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.4432 - accuracy: 0.8475\n",
      "Epoch 55: val_accuracy did not improve from 0.59443\n",
      "138/138 [==============================] - 16s 115ms/step - loss: 0.4432 - accuracy: 0.8475 - val_loss: 1.5469 - val_accuracy: 0.5577\n",
      "Epoch 56/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.4404 - accuracy: 0.8534\n",
      "Epoch 56: val_accuracy did not improve from 0.59443\n",
      "138/138 [==============================] - 16s 115ms/step - loss: 0.4404 - accuracy: 0.8534 - val_loss: 1.5253 - val_accuracy: 0.5543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.4366 - accuracy: 0.8514\n",
      "Epoch 57: val_accuracy did not improve from 0.59443\n",
      "138/138 [==============================] - 16s 112ms/step - loss: 0.4366 - accuracy: 0.8514 - val_loss: 1.5669 - val_accuracy: 0.5598\n",
      "Epoch 58/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.4300 - accuracy: 0.8575\n",
      "Epoch 58: val_accuracy did not improve from 0.59443\n",
      "138/138 [==============================] - 15s 112ms/step - loss: 0.4300 - accuracy: 0.8575 - val_loss: 1.5708 - val_accuracy: 0.5591\n",
      "Epoch 59/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.4278 - accuracy: 0.8568\n",
      "Epoch 59: val_accuracy did not improve from 0.59443\n",
      "138/138 [==============================] - 16s 112ms/step - loss: 0.4278 - accuracy: 0.8568 - val_loss: 1.5914 - val_accuracy: 0.5401\n",
      "Epoch 60/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.4353 - accuracy: 0.8573\n",
      "Epoch 60: val_accuracy did not improve from 0.59443\n",
      "138/138 [==============================] - 16s 114ms/step - loss: 0.4353 - accuracy: 0.8573 - val_loss: 1.5543 - val_accuracy: 0.5462\n",
      "Epoch 61/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.4213 - accuracy: 0.8559\n",
      "Epoch 61: val_accuracy did not improve from 0.59443\n",
      "138/138 [==============================] - 16s 115ms/step - loss: 0.4213 - accuracy: 0.8559 - val_loss: 1.5910 - val_accuracy: 0.5442\n",
      "Epoch 62/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.4149 - accuracy: 0.8616\n",
      "Epoch 62: val_accuracy did not improve from 0.59443\n",
      "138/138 [==============================] - 15s 112ms/step - loss: 0.4149 - accuracy: 0.8616 - val_loss: 1.5952 - val_accuracy: 0.5605\n",
      "Epoch 63/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.4156 - accuracy: 0.8611\n",
      "Epoch 63: val_accuracy did not improve from 0.59443\n",
      "138/138 [==============================] - 16s 114ms/step - loss: 0.4156 - accuracy: 0.8611 - val_loss: 1.5688 - val_accuracy: 0.5707\n",
      "Epoch 64/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.4034 - accuracy: 0.8641\n",
      "Epoch 64: val_accuracy did not improve from 0.59443\n",
      "138/138 [==============================] - 16s 112ms/step - loss: 0.4034 - accuracy: 0.8641 - val_loss: 1.6340 - val_accuracy: 0.5503\n",
      "Epoch 65/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.4015 - accuracy: 0.8670\n",
      "Epoch 65: val_accuracy did not improve from 0.59443\n",
      "138/138 [==============================] - 16s 113ms/step - loss: 0.4015 - accuracy: 0.8670 - val_loss: 1.5888 - val_accuracy: 0.5510\n",
      "Epoch 66/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.4083 - accuracy: 0.8609\n",
      "Epoch 66: val_accuracy did not improve from 0.59443\n",
      "138/138 [==============================] - 15s 112ms/step - loss: 0.4083 - accuracy: 0.8609 - val_loss: 1.6408 - val_accuracy: 0.5686\n",
      "Epoch 67/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.4048 - accuracy: 0.8645\n",
      "Epoch 67: val_accuracy did not improve from 0.59443\n",
      "138/138 [==============================] - 15s 112ms/step - loss: 0.4048 - accuracy: 0.8645 - val_loss: 1.6088 - val_accuracy: 0.5374\n",
      "Epoch 68/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.3930 - accuracy: 0.8679\n",
      "Epoch 68: val_accuracy did not improve from 0.59443\n",
      "138/138 [==============================] - 16s 113ms/step - loss: 0.3930 - accuracy: 0.8679 - val_loss: 1.6060 - val_accuracy: 0.5482\n",
      "Epoch 69/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.3806 - accuracy: 0.8718\n",
      "Epoch 69: val_accuracy did not improve from 0.59443\n",
      "138/138 [==============================] - 17s 121ms/step - loss: 0.3806 - accuracy: 0.8718 - val_loss: 1.6404 - val_accuracy: 0.5584\n",
      "Epoch 70/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.3937 - accuracy: 0.8686\n",
      "Epoch 70: val_accuracy did not improve from 0.59443\n",
      "138/138 [==============================] - 16s 116ms/step - loss: 0.3937 - accuracy: 0.8686 - val_loss: 1.6149 - val_accuracy: 0.5462\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(layers.Embedding(max_words, 20))\n",
    "model1.add(layers.LSTM(15,dropout=0.5))\n",
    "model1.add(layers.Dense(7,activation='softmax'))\n",
    "\n",
    "\n",
    "model1.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#Implementing model checkpoins to save the best metric and do not lose it on training.\n",
    "checkpoint1 = ModelCheckpoint(\"best_model1.hdf5\", monitor='val_accuracy', verbose=1,save_best_only=True, mode='auto', period=1,save_weights_only=False)\n",
    "history = model1.fit(X_train, y_train, epochs=70,validation_data=(X_test, y_test),callbacks=[checkpoint1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0280a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
